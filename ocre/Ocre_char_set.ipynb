{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Analyzing  character usage in OCRE coin legends\n",
        "\n",
        "This notebook analyzes the orthography of coin legends in OCRE, so that we can specify a set of accepted characters in OCRE coin legends, and reject legends that have characters outside of the specified set.  This will provide a starting point for then mapping the abbreviation-filled text of OCRE's coin legends to a parallel version with fully expanded forms (to be described in a subsequent Jupyter notebook).\n",
        "\n",
        "Valid characters can be either alphabetic characters or punctuation characters; we will reject legends that have embedded editorial notes in English, indications of lacunae or editorial restoration, or legends with content in non-Latin alphabets.\n",
        "\n",
        "The notebook uses version `2.0.1` of the `nomisma` library. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Configure Jupyter notebook\n",
        "\n",
        "Configure the notebook's repository list, and import libraries we'll use."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "// 1. Add maven repository where we can find our libraries\n",
        "val myBT = coursierapi.MavenRepository.of(\"https://dl.bintray.com/neelsmith/maven\")\n",
        "interp.repositories() ++=   \n",
        "Seq(myBT)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "// 2. Make libraries available with `$ivy` imports:\n",
        "import $ivy.`edu.holycross.shot::nomisma:2.0.1`\n",
        "//import $ivy.`edu.holycross.shot::ohco2:10.16.0`\n",
        "//import $ivy.`edu.holycross.shot.cite::xcite:4.1.1`\n",
        "import $ivy.`edu.holycross.shot::histoutils:2.2.0`\n",
        "import $ivy.`org.plotly-scala::plotly-almond:0.7.1`"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "// 3. All scala imports, and configure plotly\n",
        "import edu.holycross.shot.nomisma._\n",
        "import edu.holycross.shot.histoutils._\n",
        "\n",
        "import plotly._, plotly.element._, plotly.layout._, plotly.Almond._\n",
        "// Set display defaults suggested for use in Jupyter NBs:\n",
        "repl.pprinter() = repl.pprinter().copy(defaultHeight = 3)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the full OCRE data set\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val ocreCex = \"https://raw.githubusercontent.com/neelsmith/nomisma/master/cex/ocre-cite-ids.cex\"\n",
        "val ocre = OcreSource.fromUrl(ocreCex)\n",
        "\n",
        "// Sanity check:\n",
        "val expectedIssues = 50644\n",
        "require(ocre.size == expectedIssues) "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collect text of legends, examine character distribution\n",
        "\n",
        "To define a set of permitted characters, we begin by surveying the distribution of characters throughout all legends of the OCRE data set.\n",
        "\n",
        "We can filter `Ocre` objects to create new `Ocre` objects containing only those issues with obverse or reverse legends, and map the results to the text content of the legends.  Since the results are Vectors of Strings, we can concatenate them with `++`.\n",
        "\n",
        "In Scala, Strings are really just sequences of characters, so we can use the `toVector` function to map the text of each legend to a Vector of characters.  Scala's `flatten` function turns the results into a single Vector of Strings."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val obvLegends : Vector[String] = ocre.hasObvLegend.issues.map(_.obvLegend)\n",
        "val revLegends : Vector[String]  = ocre.hasRevLegend.issues.map(_.revLegend)\n",
        "val allLegends : Vector[String] = obvLegends ++ revLegends\n",
        "\n",
        "val allChars = allLegends.map(_.toVector).flatten\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two million characters is a lot of text: a little under 100,000 coin legends averaging about 20 characters in length."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "println(\"Obv legends: \" + obvLegends.size)\n",
        "println(\"Rev legends: \" + revLegends.size)\n",
        "println(\"All: \" + allLegends.size)\n",
        "println(\"Total characters: \" + allChars.size)\n",
        "\n",
        "println(\"Average number of characters per legend: \" + allChars.size / allLegends.size)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find how frequently individual characters occur, we use the same idiom with Scala `groupBy` that we used in making histograms of data values when we analyzed OCRE's numismatic data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val charFreqsSeq = allChars.groupBy( c => c).map{ case (c,vect) => Frequency(c, vect.size)}\n",
        "val charHistogram = edu.holycross.shot.histoutils.Histogram(charFreqsSeq.toVector).sorted\n",
        "println(\"Total distinct characters: \" + charHistogram.size)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val charValues = charHistogram.frequencies.map(_.item.toString)\n",
        "val charCounts = charHistogram.frequencies.map(_.count)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val charHistPlot = Seq(\n",
        "  Bar(x = charValues, y = charCounts)\n",
        ")\n",
        "plot(charHistPlot)\n",
        "     "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Survey usage of unusual characters\n",
        "\n",
        "The frequency plot of the 91 distinct characters has a *very* long tail.  To approach the question of which characters we should accept and which ones we should reject, we'll cut the histogram into two parts. We would expect  that the more common a character is, the more likely it is to be a valid character in an OCRE edition. (Conversely, the less common a character, the more likely it is to be some kind of error.)\n",
        "\n",
        "We'll divide the histogram at a threshold point where characters appear fewer than 600 times: that is, where individual occurrences of the character represent less than three-tenths of one percent of the two million characters in OCRE."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val threshhold = 600\n",
        "\n",
        "// Find percent of two Ints:\n",
        "def pct(i1: Int, i2: Int): Float = {\n",
        "    i1 * 100.0f / i2\n",
        "}\n",
        "\n",
        "val rareChars = charHistogram.frequencies.filter(_.count < threshhold)\n",
        "val rareTotal = edu.holycross.shot.histoutils.Histogram(rareChars).total\n",
        "val threshholdPct = pct(rareTotal, allChars.size)\n",
        "\n",
        "val lessRareChars = charHistogram.frequencies.filter(_.count >= threshhold)\n",
        "val lessRareTotal = edu.holycross.shot.histoutils.Histogram(lessRareChars).total\n",
        "val aboveThreshholdPct = 100 - threshholdPct\n",
        "\n",
        "println(\"USING THRESHHOLD VALUE OF \" + threshhold + \":\")\n",
        "println( \"Percent of character occurrences of \" + lessRareChars.size + \" characters above threshhold: \" + aboveThreshholdPct)\n",
        "println(\"Percent of character occurrences of \" + rareChars.size + \" characters below threshhold: \" + threshholdPct)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "So 25 characters account for more the 99.8% of the text content of legends in OCRE, and the remaining 66 characters in total represent less than two-tenths of one percent of the content of OCRE legends.  Let's examine the 25 frequent characters:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "for (ch <- lessRareChars) {\n",
        "    println(ch)\n",
        "}\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The space character, upper-case alphabetic characters and two punctuation marks, are all easily explained.  The appearance of lower-case alphabetic \"o\" and \"r\" is unexpected.  Let's inspect a random selection of legends where they occur:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val lowerOs = allLegends.filter(_.contains(\"o\")) \n",
        "val lowerRs =allLegends.filter(_.contains(\"r\"))\n",
        "\n",
        "println(\"Sample of ten legends with 'o's out of \" + lowerOs.size + \" (\" + pct(lowerOs.size,  allLegends.size) + \"% of legends)\")\n",
        "println(lowerOs.take(10).mkString(\"\\n\"))\n",
        "println(\"\\nSample of ten legends with 'r's out of \" + lowerRs.size + \" (\" + pct(lowerRs.size,  allLegends.size) + \"% of legends)\")\n",
        "println(lowerRs.take(10).mkString(\"\\n\"))\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like those characters only occur when the editor has inserted an English comment into the text of the legend.  We don't want to accept those characters, but the space, alphabetic characters and punctuation marks should be part of our specified set.\n",
        "\n",
        "Let's look next at the rare characters.  Are there any that we should accept?\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val distinctChars = rareChars.size + lessRareChars.size\n",
        "println( distinctChars + \" distinct chars\")\n",
        "println(rareChars.size + \" rare ones:\")\n",
        "for (ch <- rareChars) {\n",
        "    println(ch)\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The rarer characters are primarily Greek characters, lower-case (and so English-language) Latin alphabetic characters, and punctuation marking lacunae or editorial completions (such as parentheses, brackets, ellipses).  We want to omit legends containing any of these\n",
        "\n",
        "Two rare characters are used as punctuation marks that we can process like the more frequent punctuation marks we have already observed, namely  `←` and `|`.\n",
        "\n",
        "We can now compile a list of all acceptable characters, and define a function to determine if a String value is composed exclusively of valid characters or not.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val allowedChars = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ -•←|\"\n",
        "\n",
        "// True if String s composed only of allowable characters\n",
        "def validOrtho(s: String, allowedCharacters: String = allowedChars) : Boolean = {\n",
        " \n",
        "    val charChecks = for (c <- s.toVector) yield {\n",
        "        allowedCharacters.contains(c)\n",
        "    }\n",
        "    val flatVals = charChecks.distinct\n",
        "    (flatVals.size == 1) && (flatVals(0)== true)\n",
        "}\n",
        "println(\"Total valid characters: \" + allowedChars.size)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary of orthographic validity of OCRE coin legends\n",
        "\n",
        "We can now apply our `validOrtho` function to all coin legends in OCRE.\n",
        "\n",
        "Of the 98,566 legends in OCRE, 96.6% are composed solely using the 31 characters we specified as valid.  Almost 3.4% include one or more of the 60 characters we defined as invalid."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "val total = allLegends.size\n",
        "val sheep = allLegends.filter(leg => validOrtho(leg))\n",
        "val goats = allLegends.filterNot(leg => validOrtho(leg))\n",
        "\n",
        "val sheepPct = sheep.size * 100.0f / allLegends.size\n",
        "val goatsPct = goats.size * 100.0f / allLegends.size\n",
        "println(\"Sheep: \" + sheep.size + \" (\" + sheepPct + \"% of \" + allLegends.size + \")\")\n",
        "println(\"Goats: \" + goats.size + \" (\" + goatsPct + \"% of \" + allLegends.size + \")\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "scala212"
    },
    "kernelspec": {
      "name": "scala212",
      "language": "scala",
      "display_name": "Scala212 (almond)"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "nbconvert_exporter": "script",
      "version": "2.12.10"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}